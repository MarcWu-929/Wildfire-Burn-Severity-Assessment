{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205b24cf-9dd0-40ab-b5d5-7a0dfb9d5f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from osgeo import gdal\n",
    "import pandas as pd\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import class_weight\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597b3831-4616-48e4-8390-0312589c0abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = []\n",
    "image_names = glob.glob(r\"C:\\Document\\University\\2023_Spring_Junior\\GEOG_491\\Dataset\\August_Complex\\Deep_learning\\256\\training_image\\images/*.tif\")\n",
    "image_names.sort()\n",
    "for img_path in image_names:\n",
    "      # print(img_path)\n",
    "      tiff_image = gdal.Open(img_path, 0)\n",
    "      band7 = tiff_image.GetRasterBand(7).ReadAsArray()\n",
    "      band8 = tiff_image.GetRasterBand(8).ReadAsArray()\n",
    "      band9 = tiff_image.GetRasterBand(9).ReadAsArray()\n",
    "\n",
    "      X = np.stack((band9, band8, band7), axis=-1)\n",
    "      train_images.append(X)\n",
    "\n",
    "train_images = np.array(train_images)\n",
    "print(np.mean(train_images))\n",
    "# train_images = train_images / (2**16-1)\n",
    "# train_images = train_images.astype(int)\n",
    "\n",
    "# normalize\n",
    "# low, high = np.percentile(X, (2, 98))\n",
    "# train_images = (train_images-low)/(high-low)\n",
    "X_train = train_images\n",
    "print(X_train.shape)\n",
    "\n",
    "train_masks = []\n",
    "image_names = glob.glob(r\"C:\\Document\\University\\2023_Spring_Junior\\GEOG_491\\Dataset\\August_Complex\\Deep_learning\\mask\\ps\\binary\\truth_2\\training\\images/*.tif\")\n",
    "image_names.sort()\n",
    "for img_path in image_names:\n",
    "  #  print(img_path)\n",
    "   tiff_image = gdal.Open(img_path, 0)\n",
    "   band1 = tiff_image.GetRasterBand(1).ReadAsArray()\n",
    "   train_masks.append(band1)\n",
    "\n",
    "train_masks = np.array(train_masks)\n",
    "y_train = train_masks\n",
    "print(y_train.shape)\n",
    "\n",
    "y_train_cat = to_categorical(train_masks, num_classes=2)\n",
    "y_train_cat = y_train_cat.astype(int)\n",
    "print(y_train_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea979463-3b8f-4edd-8fe5-4c001582067b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_pre = []\n",
    "image_names = glob.glob(r\"C:\\Document\\University\\2023_Spring_Junior\\GEOG_491\\Dataset\\August_Complex\\Deep_learning\\256\\pre\\training\\images/*.tif\")\n",
    "image_names.sort()\n",
    "for img_path in image_names:\n",
    "      # print(img_path)\n",
    "      tiff_image = gdal.Open(img_path, 0)\n",
    "      band7 = tiff_image.GetRasterBand(7).ReadAsArray()\n",
    "      band8 = tiff_image.GetRasterBand(8).ReadAsArray()\n",
    "      band9 = tiff_image.GetRasterBand(9).ReadAsArray()\n",
    "\n",
    "      X = np.stack((band9, band8, band7), axis=-1)\n",
    "      train_images_pre.append(X)\n",
    "\n",
    "train_images_pre = np.array(train_images_pre)\n",
    "print(np.mean(train_images_pre))\n",
    "# train_images_pre = train_images_pre / (2**16-1)\n",
    "# train_images_pre = train_images_pre.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e62b482-ffe4-4f67-a0fd-7de27e0116c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_nbr = []\n",
    "image_names = glob.glob(r\"C:\\Document\\University\\2023_Spring_Junior\\GEOG_491\\Dataset\\August_Complex\\Deep_learning\\mask\\ps\\NBR\\train\\images/*.tif\")\n",
    "image_names.sort()\n",
    "for img_path in image_names:\n",
    "      # print(img_path)\n",
    "      tiff_image = gdal.Open(img_path, 0)\n",
    "      band1 = tiff_image.GetRasterBand(1).ReadAsArray()\n",
    "      band2 = tiff_image.GetRasterBand(2).ReadAsArray()\n",
    "      band3 = tiff_image.GetRasterBand(3).ReadAsArray()\n",
    "\n",
    "      X = np.stack((band1, band2, band3), axis=-1)\n",
    "      train_images_nbr.append(X)\n",
    "\n",
    "train_images_nbr = np.array(train_images_nbr)\n",
    "\n",
    "# train_images_nbr = train_images_nbr / (2**16-1)\n",
    "# train_images_nbr = train_images_nbr / np.max(train_images_nbr)\n",
    "# train_images_nbr = np.where(train_images_nbr < 0, 0, train_images_nbr)\n",
    "# train_images_nbr = np.nan_to_num(train_images_nbr, nan=0)\n",
    "\n",
    "#stretch\n",
    "# min_val = np.min(train_images_nbr)\n",
    "# max_val = np.max(train_images_nbr)\n",
    "# train_images_nbr = (train_images_nbr - min_val) / (max_val - min_val)\n",
    "train_images_nbr = np.nan_to_num(train_images_nbr, nan=0.0)\n",
    "print(np.mean(train_images_nbr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e1b612-c585-4078-88de-f56d5685614e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sanity check, view few images\n",
    "import random\n",
    "import numpy as np\n",
    "image_number = random.randint(0, len(train_images)-1)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(121)\n",
    "plt.imshow(np.reshape((train_images[image_number, :, :, 2]), (256, 256, 1)))\n",
    "plt.subplot(122)\n",
    "plt.imshow(np.reshape(train_masks[image_number], (256, 256, 1)))\n",
    "plt.show()\n",
    "print(image_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6425a47-57db-43d4-a508-31ffc801c8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = []\n",
    "image_names = glob.glob(r\"C:\\Document\\University\\2023_Spring_Junior\\GEOG_491\\Dataset\\August_Complex\\Deep_learning\\256\\testing_image\\images/*.tif\")\n",
    "image_names.sort()\n",
    "for img_path in image_names:\n",
    "      # print(img_path)\n",
    "      tiff_image = gdal.Open(img_path, 0)\n",
    "      band7 = tiff_image.GetRasterBand(7).ReadAsArray()\n",
    "      band8 = tiff_image.GetRasterBand(8).ReadAsArray()\n",
    "      band9 = tiff_image.GetRasterBand(9).ReadAsArray()\n",
    "\n",
    "      X = np.stack((band9, band8, band7), axis=-1)\n",
    "      test_images.append(X)\n",
    "\n",
    "test_images = np.array(test_images)\n",
    "print(np.mean(test_images))\n",
    "# normalize\n",
    "# test_images = test_images / (2**16-1)\n",
    "# test_images = test_images.astype(int)\n",
    "# low, high = np.percentile(X, (2, 98))\n",
    "# test_images = (test_images-low)/(high-low)\n",
    "print(test_images.shape)\n",
    "\n",
    "test_masks = []\n",
    "image_names = glob.glob(r\"C:\\Document\\University\\2023_Spring_Junior\\GEOG_491\\Dataset\\August_Complex\\Deep_learning\\mask\\ps\\binary\\truth_2\\testing\\images/*.tif\")\n",
    "image_names.sort()\n",
    "for img_path in image_names:\n",
    "  #  print(img_path)\n",
    "   tiff_image = gdal.Open(img_path, 0)\n",
    "   band1 = tiff_image.GetRasterBand(1).ReadAsArray()\n",
    "   test_masks.append(band1)\n",
    "\n",
    "test_masks = np.array(test_masks)\n",
    "# test_masks = test_masks\n",
    "# masks = train_masks.astype(int)\n",
    "print(np.unique(test_masks))\n",
    "\n",
    "y_test_cat = to_categorical(test_masks, num_classes=2)\n",
    "y_test_cat = y_test_cat.astype(int)\n",
    "print(y_test_cat.shape)\n",
    "print(np.unique(y_test_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df142923-10e3-49f8-b71d-f57592cf5030",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_pre = []\n",
    "image_names = glob.glob(r\"C:\\Document\\University\\2023_Spring_Junior\\GEOG_491\\Dataset\\August_Complex\\Deep_learning\\256\\pre\\testing\\images/*.tif\")\n",
    "image_names.sort()\n",
    "for img_path in image_names:\n",
    "      # print(img_path)\n",
    "      tiff_image = gdal.Open(img_path, 0)\n",
    "      band7 = tiff_image.GetRasterBand(7).ReadAsArray()\n",
    "      band8 = tiff_image.GetRasterBand(8).ReadAsArray()\n",
    "      band9 = tiff_image.GetRasterBand(9).ReadAsArray()\n",
    "\n",
    "      X = np.stack((band9, band8, band7), axis=-1)\n",
    "      test_images_pre.append(X)\n",
    "\n",
    "test_images_pre = np.array(test_images_pre)\n",
    "print(np.mean(test_images_pre))\n",
    "# normalize\n",
    "# test_images_pre = test_images / (2**16-1)\n",
    "# test_images_pre = test_images_pre.astype(int)\n",
    "# low, high = np.percentile(X, (2, 98))\n",
    "# test_images = (test_images-low)/(high-low)\n",
    "print(test_images_pre.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b194ce6e-b813-49ca-b7aa-d6fb8d9f58f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_nbr = []\n",
    "image_names = glob.glob(r\"C:\\Document\\University\\2023_Spring_Junior\\GEOG_491\\Dataset\\August_Complex\\Deep_learning\\mask\\ps\\NBR\\test\\images/*.tif\")\n",
    "# /content/drive/MyDrive/Colab Notebooks/Deep_learning/256/ps/nbr/test/images\n",
    "# /content/drive/MyDrive/Colab Notebooks/Deep_learning/256/ps/BAIS/test/images\n",
    "image_names.sort()\n",
    "for img_path in image_names:\n",
    "      # print(img_path)\n",
    "      tiff_image = gdal.Open(img_path, 0)\n",
    "      band1 = tiff_image.GetRasterBand(1).ReadAsArray()\n",
    "      band2 = tiff_image.GetRasterBand(2).ReadAsArray()\n",
    "      band3 = tiff_image.GetRasterBand(3).ReadAsArray()\n",
    "\n",
    "      X = np.stack((band1, band2, band3), axis=-1)\n",
    "      test_images_nbr.append(X)\n",
    "\n",
    "test_images_nbr = np.array(test_images_nbr)\n",
    "\n",
    "# test_images_nbr = test_images_nbr / (2**16-1)\n",
    "# test_images_nbr = test_images_nbr / np.max(test_images_nbr)\n",
    "# test_images_nbr = np.where(test_images_nbr < 0, 0, test_images_nbr)\n",
    "\n",
    "#stretch\n",
    "# min_val = np.min(test_images_nbr)\n",
    "# max_val = np.max(test_images_nbr)\n",
    "# test_images_nbr = (test_images_nbr - min_val) / (max_val - min_val)\n",
    "print(np.mean(test_images_nbr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaea5d75-738f-43fd-a704-1902c45e687e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Sanity check, view few images\n",
    "image_number = random.randint(0, len(test_images)-1)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(121)\n",
    "plt.imshow(np.reshape((test_images[image_number, :, :, 2]), (256, 256, 1)))\n",
    "plt.subplot(122)\n",
    "plt.imshow(np.reshape(test_masks[image_number], (256, 256, 1)))\n",
    "plt.show()\n",
    "print(image_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1810a3-c296-4de2-b898-5911fb4890d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Activation, multiply\n",
    "# def attention_block(x, g):\n",
    "#     theta_x = Conv2D(filters=8, kernel_size=(1, 1), strides=(1, 1), padding='same')(x)\n",
    "#     phi_g = Conv2D(filters=8, kernel_size=(1, 1), strides=(1, 1), padding='same')(g)\n",
    "#     f = Activation('relu')(theta_x + phi_g)\n",
    "#     psi_f = Conv2D(filters=1, kernel_size=(1, 1), strides=(1, 1), padding='same')(f)\n",
    "#     attention_weights = Activation('softmax')(psi_f)\n",
    "#     attention_output = multiply([x, attention_weights])\n",
    "#     return attention_output\n",
    "\n",
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate, Add\n",
    "# def residual_block(input_layer, filters):\n",
    "#     conv1 = Conv2D(filters, kernel_size=(3, 3), activation='relu', padding='same')(input_layer)\n",
    "#     conv2 = Conv2D(filters, kernel_size=(3, 3), activation='relu', padding='same')(conv1)\n",
    "#     residual = Add()([conv2, input_layer])\n",
    "#     return residual\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers, regularizers\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def conv_block(x, filter_size, size, dropout, batch_norm=False):\n",
    "\n",
    "    conv = layers.Conv2D(size, (filter_size, filter_size), padding=\"same\")(x)\n",
    "    if batch_norm is True:\n",
    "        conv = layers.BatchNormalization(axis=3)(conv)\n",
    "    conv = layers.Activation(\"relu\")(conv)\n",
    "\n",
    "    conv = layers.Conv2D(size, (filter_size, filter_size), padding=\"same\")(conv)\n",
    "    if batch_norm is True:\n",
    "        conv = layers.BatchNormalization(axis=3)(conv)\n",
    "    conv = layers.Activation(\"relu\")(conv)\n",
    "\n",
    "    if dropout > 0:\n",
    "        conv = layers.Dropout(dropout)(conv)\n",
    "\n",
    "    return conv\n",
    "\n",
    "\n",
    "def repeat_elem(tensor, rep):\n",
    "    # lambda function to repeat Repeats the elements of a tensor along an axis\n",
    "    #by a factor of rep.\n",
    "    # If tensor has shape (None, 256,256,3), lambda will return a tensor of shape\n",
    "    #(None, 256,256,6), if specified axis=3 and rep=2.\n",
    "\n",
    "     return layers.Lambda(lambda x, repnum: K.repeat_elements(x, repnum, axis=3),\n",
    "                          arguments={'repnum': rep})(tensor)\n",
    "\n",
    "def gating_signal(input, out_size, batch_norm=False):\n",
    "    \"\"\"\n",
    "    resize the down layer feature map into the same dimension as the up layer feature map\n",
    "    using 1x1 conv\n",
    "    :return: the gating feature map with the same dimension of the up layer feature map\n",
    "    \"\"\"\n",
    "    x = layers.Conv2D(out_size, (1, 1), padding='same')(input)\n",
    "    if batch_norm:\n",
    "        x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def attention_block(x, gating, inter_shape):\n",
    "    shape_x = K.int_shape(x)\n",
    "    shape_g = K.int_shape(gating)\n",
    "\n",
    "# Getting the x signal to the same shape as the gating signal\n",
    "    theta_x = layers.Conv2D(inter_shape, (2, 2), strides=(2, 2), padding='same')(x)  # 16\n",
    "    shape_theta_x = K.int_shape(theta_x)\n",
    "\n",
    "# Getting the gating signal to the same number of filters as the inter_shape\n",
    "    phi_g = layers.Conv2D(inter_shape, (1, 1), padding='same')(gating)\n",
    "    upsample_g = layers.Conv2DTranspose(inter_shape, (3, 3),\n",
    "                                 strides=(shape_theta_x[1] // shape_g[1], shape_theta_x[2] // shape_g[2]),\n",
    "                                 padding='same')(phi_g)  # 16\n",
    "\n",
    "    concat_xg = layers.add([upsample_g, theta_x])\n",
    "    act_xg = layers.Activation('relu')(concat_xg)\n",
    "    psi = layers.Conv2D(1, (1, 1), padding='same')(act_xg)\n",
    "    sigmoid_xg = layers.Activation('sigmoid')(psi)\n",
    "    shape_sigmoid = K.int_shape(sigmoid_xg)\n",
    "    upsample_psi = layers.UpSampling2D(size=(shape_x[1] // shape_sigmoid[1], shape_x[2] // shape_sigmoid[2]))(sigmoid_xg)  # 32\n",
    "\n",
    "    upsample_psi = repeat_elem(upsample_psi, shape_x[3])\n",
    "\n",
    "    y = layers.multiply([upsample_psi, x])\n",
    "\n",
    "    result = layers.Conv2D(shape_x[3], (1, 1), padding='same')(y)\n",
    "    result_bn = layers.BatchNormalization()(result)\n",
    "    return result_bn\n",
    "\n",
    "def res_conv_block(x, filter_size, size, dropout, batch_norm=False):\n",
    "    '''\n",
    "    Residual convolutional layer.\n",
    "    Two variants....\n",
    "    Either put activation function before the addition with shortcut\n",
    "    or after the addition (which would be as proposed in the original resNet).\n",
    "\n",
    "    1. conv - BN - Activation - conv - BN - Activation\n",
    "                                          - shortcut  - BN - shortcut+BN\n",
    "\n",
    "    2. conv - BN - Activation - conv - BN\n",
    "                                     - shortcut  - BN - shortcut+BN - Activation\n",
    "\n",
    "    Check fig 4 in https://arxiv.org/ftp/arxiv/papers/1802/1802.06955.pdf\n",
    "    '''\n",
    "\n",
    "    conv = layers.Conv2D(size, (filter_size, filter_size), padding='same')(x)\n",
    "    if batch_norm is True:\n",
    "        conv = layers.BatchNormalization(axis=3)(conv)\n",
    "    conv = layers.Activation('relu')(conv)\n",
    "\n",
    "    conv = layers.Conv2D(size, (filter_size, filter_size), padding='same')(conv)\n",
    "    if batch_norm is True:\n",
    "        conv = layers.BatchNormalization(axis=3)(conv)\n",
    "    #conv = layers.Activation('relu')(conv)    #Activation before addition with shortcut\n",
    "    if dropout > 0:\n",
    "        conv = layers.Dropout(dropout)(conv)\n",
    "\n",
    "    shortcut = layers.Conv2D(size, kernel_size=(1, 1), padding='same')(x)\n",
    "    if batch_norm is True:\n",
    "        shortcut = layers.BatchNormalization(axis=3)(shortcut)\n",
    "\n",
    "    res_path = layers.add([shortcut, conv])\n",
    "    res_path = layers.Activation('relu')(res_path)    #Activation after addition with shortcut (Original residual block)\n",
    "    return res_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab14d0a0-dc21-46fc-8363-9552a1ccdf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Attention_UNet(input_shape, NUM_CLASSES=2, dropout_rate=0.0, batch_norm=True):\n",
    "    '''\n",
    "    Attention UNet,\n",
    "\n",
    "    '''\n",
    "    # network structure\n",
    "    FILTER_NUM = 16 # number of basic filters for the first layer\n",
    "    FILTER_SIZE = 3 # size of the convolutional filter\n",
    "    UP_SAMP_SIZE = 2 # size of upsampling filters\n",
    "\n",
    "    input1 = layers.Input(input_shape)\n",
    "\n",
    "    # Downsampling layers post\n",
    "    # DownRes 1, convolution + pooling\n",
    "    conv_128_1 = conv_block(input1, FILTER_SIZE, FILTER_NUM, dropout_rate, batch_norm)\n",
    "    pool_64_1 = layers.MaxPooling2D(pool_size=(2,2))(conv_128_1)\n",
    "    # DownRes 2\n",
    "    conv_64_1 = conv_block(pool_64_1, FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm)\n",
    "    pool_32_1 = layers.MaxPooling2D(pool_size=(2,2))(conv_64_1)\n",
    "    # DownRes 3\n",
    "    conv_32_1 = conv_block(pool_32_1, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)\n",
    "    pool_16_1 = layers.MaxPooling2D(pool_size=(2,2))(conv_32_1)\n",
    "    # DownRes 4\n",
    "    conv_16_1 = conv_block(pool_16_1, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)\n",
    "    pool_8_1 = layers.MaxPooling2D(pool_size=(2,2))(conv_16_1)\n",
    "    # DownRes 5, convolution only\n",
    "    conv_8_1 = conv_block(pool_8_1, FILTER_SIZE, 16*FILTER_NUM, dropout_rate, batch_norm)\n",
    "\n",
    "    # Downsampling layers pre\n",
    "    input2 = layers.Input(input_shape)\n",
    "    # DownRes 1, convolution + pooling\n",
    "    conv_128_2 = conv_block(input2, FILTER_SIZE, FILTER_NUM, dropout_rate, batch_norm)\n",
    "    pool_64_2 = layers.MaxPooling2D(pool_size=(2,2))(conv_128_2)\n",
    "    # DownRes 2\n",
    "    conv_64_2 = conv_block(pool_64_2, FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm)\n",
    "    pool_32_2 = layers.MaxPooling2D(pool_size=(2,2))(conv_64_2)\n",
    "    # DownRes 3\n",
    "    conv_32_2 = conv_block(pool_32_2, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)\n",
    "    pool_16_2 = layers.MaxPooling2D(pool_size=(2,2))(conv_32_2)\n",
    "    # DownRes 4\n",
    "    conv_16_2 = conv_block(pool_16_2, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)\n",
    "    pool_8_2 = layers.MaxPooling2D(pool_size=(2,2))(conv_16_2)\n",
    "    # DownRes 5, convolution only\n",
    "    conv_8_2 = conv_block(pool_8_2, FILTER_SIZE, 16*FILTER_NUM, dropout_rate, batch_norm)\n",
    "\n",
    "    # Downsampling layers nbr\n",
    "    input3 = layers.Input(input_shape)\n",
    "    # DownRes 1, convolution + pooling\n",
    "    conv_128_3 = conv_block(input2, FILTER_SIZE, FILTER_NUM, dropout_rate, batch_norm)\n",
    "    pool_64_3 = layers.MaxPooling2D(pool_size=(2,2))(conv_128_3)\n",
    "    # DownRes 2\n",
    "    conv_64_3 = conv_block(pool_64_3, FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm)\n",
    "    pool_32_3 = layers.MaxPooling2D(pool_size=(2,2))(conv_64_3)\n",
    "    # DownRes 3\n",
    "    conv_32_3 = conv_block(pool_32_3, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)\n",
    "    pool_16_3 = layers.MaxPooling2D(pool_size=(2,2))(conv_32_3)\n",
    "    # DownRes 4\n",
    "    conv_16_3 = conv_block(pool_16_3, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)\n",
    "    pool_8_3 = layers.MaxPooling2D(pool_size=(2,2))(conv_16_3)\n",
    "    # DownRes 5, convolution only\n",
    "    conv_8_3 = conv_block(pool_8_3, FILTER_SIZE, 16*FILTER_NUM, dropout_rate, batch_norm)\n",
    "\n",
    "    x8 = concatenate([conv_8_1, conv_8_2, conv_8_3])\n",
    "    x16 = concatenate([conv_16_1, conv_16_2, conv_16_3])\n",
    "    x32 = concatenate([conv_32_1, conv_32_2, conv_32_3])\n",
    "    x64 = concatenate([conv_64_1, conv_64_2, conv_64_3])\n",
    "    x128 = concatenate([conv_128_1, conv_128_2, conv_128_3])\n",
    "\n",
    "    # Upsampling layers\n",
    "    # UpRes 6, attention gated concatenation + upsampling + double residual convolution\n",
    "    gating_16 = gating_signal(x8, 8*FILTER_NUM, batch_norm)\n",
    "    att_16 = attention_block(x16, gating_16, 8*FILTER_NUM)\n",
    "    up_16 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(x8)\n",
    "    up_16 = layers.concatenate([up_16, att_16], axis=3)\n",
    "    up_conv_16 = conv_block(up_16, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)\n",
    "    # UpRes 7\n",
    "    gating_32 = gating_signal(up_conv_16, 4*FILTER_NUM, batch_norm)\n",
    "    att_32 = attention_block(x32, gating_32, 4*FILTER_NUM)\n",
    "    up_32 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_16)\n",
    "    up_32 = layers.concatenate([up_32, att_32], axis=3)\n",
    "    up_conv_32 = conv_block(up_32, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)\n",
    "    # UpRes 8\n",
    "    gating_64 = gating_signal(up_conv_32, 2*FILTER_NUM, batch_norm)\n",
    "    att_64 = attention_block(x64, gating_64, 2*FILTER_NUM)\n",
    "    up_64 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_32)\n",
    "    up_64 = layers.concatenate([up_64, att_64], axis=3)\n",
    "    up_conv_64 = conv_block(up_64, FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm)\n",
    "    # UpRes 9\n",
    "    gating_128 = gating_signal(up_conv_64, FILTER_NUM, batch_norm)\n",
    "    att_128 = attention_block(x128, gating_128, FILTER_NUM)\n",
    "    up_128 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_64)\n",
    "    up_128 = layers.concatenate([up_128, att_128], axis=3)\n",
    "    up_conv_128 = conv_block(up_128, FILTER_SIZE, FILTER_NUM, dropout_rate, batch_norm)\n",
    "\n",
    "    # 1*1 convolutional layers\n",
    "    conv_final = layers.Conv2D(NUM_CLASSES, kernel_size=(1,1))(up_conv_128)\n",
    "    conv_final = layers.BatchNormalization(axis=3)(conv_final)\n",
    "    conv_final = layers.Activation('softmax')(conv_final)  #Change to softmax for multichannel\n",
    "\n",
    "    # Model integration\n",
    "    model = models.Model(inputs=[input1, input2, input3], outputs=[conv_final], name=\"Attention_UNet\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762191c6-2ef0-4f29-a7e8-c143962bcdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Attention_ResUNet(input_shape, NUM_CLASSES=2, dropout_rate=0.2, batch_norm=True):\n",
    "    '''\n",
    "    Attention_ResUNet,\n",
    "\n",
    "    '''\n",
    "    # network structure\n",
    "    FILTER_NUM = 16 # number of basic filters for the first layer\n",
    "    FILTER_SIZE = 3 # size of the convolutional filter\n",
    "    UP_SAMP_SIZE = 2 # size of upsampling filters\n",
    "\n",
    "    input1 = layers.Input(input_shape)\n",
    "\n",
    "    # Downsampling layers post\n",
    "    # DownRes 1, convolution + pooling\n",
    "    conv_128_1 = res_conv_block(input1, FILTER_SIZE, FILTER_NUM, dropout_rate, batch_norm)\n",
    "    pool_64_1 = layers.MaxPooling2D(pool_size=(2,2))(conv_128_1)\n",
    "    # DownRes 2\n",
    "    conv_64_1 = res_conv_block(pool_64_1, FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm)\n",
    "    pool_32_1 = layers.MaxPooling2D(pool_size=(2,2))(conv_64_1)\n",
    "    # DownRes 3\n",
    "    conv_32_1 = res_conv_block(pool_32_1, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)\n",
    "    pool_16_1 = layers.MaxPooling2D(pool_size=(2,2))(conv_32_1)\n",
    "    # DownRes 4\n",
    "    conv_16_1 = res_conv_block(pool_16_1, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)\n",
    "    pool_8_1 = layers.MaxPooling2D(pool_size=(2,2))(conv_16_1)\n",
    "    # DownRes 5, convolution only\n",
    "    conv_8_1 = res_conv_block(pool_8_1, FILTER_SIZE, 16*FILTER_NUM, dropout_rate, batch_norm)\n",
    "\n",
    "    # Downsampling layers pre\n",
    "    input2 = layers.Input(input_shape)\n",
    "    # DownRes 1, convolution + pooling\n",
    "    conv_128_2 = res_conv_block(input2, FILTER_SIZE, FILTER_NUM, dropout_rate, batch_norm)\n",
    "    pool_64_2 = layers.MaxPooling2D(pool_size=(2,2))(conv_128_2)\n",
    "    # DownRes 2\n",
    "    conv_64_2 = res_conv_block(pool_64_2, FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm)\n",
    "    pool_32_2 = layers.MaxPooling2D(pool_size=(2,2))(conv_64_2)\n",
    "    # DownRes 3\n",
    "    conv_32_2 = res_conv_block(pool_32_2, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)\n",
    "    pool_16_2 = layers.MaxPooling2D(pool_size=(2,2))(conv_32_2)\n",
    "    # DownRes 4\n",
    "    conv_16_2 = res_conv_block(pool_16_2, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)\n",
    "    pool_8_2 = layers.MaxPooling2D(pool_size=(2,2))(conv_16_2)\n",
    "    # DownRes 5, convolution only\n",
    "    conv_8_2 = res_conv_block(pool_8_2, FILTER_SIZE, 16*FILTER_NUM, dropout_rate, batch_norm)\n",
    "\n",
    "    # Downsampling layers nbr\n",
    "    # input3 = layers.Input(input_shape)\n",
    "    # # DownRes 1, convolution + pooling\n",
    "    # conv_128_3 = res_conv_block(input2, FILTER_SIZE, FILTER_NUM, dropout_rate, batch_norm)\n",
    "    # pool_64_3 = layers.MaxPooling2D(pool_size=(2,2))(conv_128_3)\n",
    "    # # DownRes 2\n",
    "    # conv_64_3 = res_conv_block(pool_64_3, FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm)\n",
    "    # pool_32_3 = layers.MaxPooling2D(pool_size=(2,2))(conv_64_3)\n",
    "    # # DownRes 3\n",
    "    # conv_32_3 = res_conv_block(pool_32_3, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)\n",
    "    # pool_16_3 = layers.MaxPooling2D(pool_size=(2,2))(conv_32_3)\n",
    "    # # DownRes 4\n",
    "    # conv_16_3 = res_conv_block(pool_16_3, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)\n",
    "    # pool_8_3 = layers.MaxPooling2D(pool_size=(2,2))(conv_16_3)\n",
    "    # # DownRes 5, convolution only\n",
    "    # conv_8_3 = res_conv_block(pool_8_3, FILTER_SIZE, 16*FILTER_NUM, dropout_rate, batch_norm)\n",
    "\n",
    "    x8 = concatenate([conv_8_1, conv_8_2])\n",
    "    x16 = concatenate([conv_16_1, conv_16_2])\n",
    "    x32 = concatenate([conv_32_1, conv_32_2])\n",
    "    x64 = concatenate([conv_64_1, conv_64_2])\n",
    "    x128 = concatenate([conv_128_1, conv_128_2])\n",
    "\n",
    "    # Upsampling layers\n",
    "    # UpRes 6, attention gated concatenation + upsampling + double residual convolution\n",
    "    gating_16 = gating_signal(x8, 8*FILTER_NUM, batch_norm)\n",
    "    att_16 = attention_block(x16, gating_16, 8*FILTER_NUM)\n",
    "    up_16 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(x8)\n",
    "    up_16 = layers.concatenate([up_16, att_16], axis=3)\n",
    "    up_conv_16 = res_conv_block(up_16, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)\n",
    "    # UpRes 7\n",
    "    gating_32 = gating_signal(up_conv_16, 4*FILTER_NUM, batch_norm)\n",
    "    att_32 = attention_block(x32, gating_32, 4*FILTER_NUM)\n",
    "    up_32 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_16)\n",
    "    up_32 = layers.concatenate([up_32, att_32], axis=3)\n",
    "    up_conv_32 = res_conv_block(up_32, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)\n",
    "    # UpRes 8\n",
    "    gating_64 = gating_signal(up_conv_32, 2*FILTER_NUM, batch_norm)\n",
    "    att_64 = attention_block(x64, gating_64, 2*FILTER_NUM)\n",
    "    up_64 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_32)\n",
    "    up_64 = layers.concatenate([up_64, att_64], axis=3)\n",
    "    up_conv_64 = res_conv_block(up_64, FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm)\n",
    "    # UpRes 9\n",
    "    gating_128 = gating_signal(up_conv_64, FILTER_NUM, batch_norm)\n",
    "    att_128 = attention_block(x128, gating_128, FILTER_NUM)\n",
    "    up_128 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_64)\n",
    "    up_128 = layers.concatenate([up_128, att_128], axis=3)\n",
    "    up_conv_128 = res_conv_block(up_128, FILTER_SIZE, FILTER_NUM, dropout_rate, batch_norm)\n",
    "\n",
    "    # 1*1 convolutional layers\n",
    "    conv_final = layers.Conv2D(NUM_CLASSES, kernel_size=(1,1))(up_conv_128)\n",
    "    conv_final = layers.BatchNormalization(axis=3)(conv_final)\n",
    "    conv_final = layers.Activation('softmax')(conv_final)  #Change to softmax for multichannel\n",
    "\n",
    "    # Model integration\n",
    "    model = models.Model(inputs=[input1, input2], outputs=[conv_final], name=\"Attention_ResUNet\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399124d6-63ff-4ab9-985a-cd03674da6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "def categorical_mean_iou_loss(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, y_pred.dtype)  # Convert y_true to the same data type as y_pred\n",
    "\n",
    "    # Calculate intersection and union\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=[1, 2])\n",
    "    union = K.sum(y_true, axis=[1, 2]) + K.sum(y_pred, axis=[1, 2]) - intersection\n",
    "\n",
    "    # Calculate mean IoU loss\n",
    "    iou = (intersection + K.epsilon()) / (union + K.epsilon())\n",
    "    mean_iou_loss = 1 - K.mean(iou)\n",
    "\n",
    "    return mean_iou_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078d9e54-23a7-4068-87dc-cc9f6a92f6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMeanIOU(tf.keras.metrics.MeanIoU):\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        return super().update_state(tf.argmax(y_true, axis=-1), tf.argmax(y_pred, axis=-1), sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb033601-a567-457b-88d9-49c95485b866",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "\n",
    "# Custom callback to stop training at a specific validation accuracy\n",
    "class StopAtValidationAccuracy(Callback):\n",
    "    def __init__(self, target_accuracy):\n",
    "        super(StopAtValidationAccuracy, self).__init__()\n",
    "        self.target_accuracy = target_accuracy\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs['val_my_mean_iou'] >= self.target_accuracy:\n",
    "            self.model.stop_training = True\n",
    "            print(f\"\\nReached target validation accuracy ({self.target_accuracy}), stopping training!\")\n",
    "\n",
    "# Define the custom callback with the desired target validation accuracy\n",
    "target_accuracy = 0.91\n",
    "stop_at_accuracy = StopAtValidationAccuracy(target_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a86d4e-322a-4063-9d3b-6fb0d4572d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.000001)\n",
    "# def get_model():\n",
    "#     return multi_unet_model(n_classes=4, IMG_HEIGHT=256, IMG_WIDTH=256, IMG_CHANNELS=3)\n",
    "# def get_model():\n",
    "#     return Attention_UNet((256, 256, 3))\n",
    "def get_model():\n",
    "    return Attention_ResUNet((256, 256, 3))\n",
    "# def get_model():\n",
    "#     return Attention_ResUNet_stacked((256, 256, 9))\n",
    "model = get_model()\n",
    "model.compile(optimizer = 'adam', loss=categorical_mean_iou_loss, metrics = [MyMeanIOU(2)])\n",
    "# tf.keras.losses.CategoricalCrossentropy()\n",
    "# categorical_focal_loss(gamma=2.0, alpha=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "57a1b8bf20236e65"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ee41f8-4553-4b88-bfe3-0c23fec5112c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = [X_train, train_images_pre]\n",
    "test_list = [test_images, test_images_pre]\n",
    "# train_list = [X_train, train_images_pre, train_images_nbr]\n",
    "# test_list = [test_images, test_images_pre, test_images_nbr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4923eed8-966c-411a-bdf0-23719db23645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting model\n",
    "import time\n",
    "start_time = time.time()\n",
    "history = model.fit(train_list, y_train_cat,\n",
    "                    batch_size = 8,\n",
    "                    verbose=1,\n",
    "                    epochs=50,\n",
    "                    validation_data=(test_list, y_test_cat),\n",
    "                    callbacks=[stop_at_accuracy],\n",
    "                    shuffle=True)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(\"Training time: {:.2f} seconds\".format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2f8596-3987-4fd5-97d6-179426801760",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(r\"C:\\Document\\University\\2023_Spring_Junior\\GEOG_491\\Dataset\\August_Complex\\Deep_learning\\models_new\\binary\\ra_unet_binary.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a3d989-e6d2-4478-b94b-5adbdefd7666",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "predicted = np.expand_dims(test_images, 0)\n",
    "prediction = (model.predict(test_list))\n",
    "print(prediction.shape)\n",
    "predicted_img = np.argmax(prediction, axis=3)[:,:,:]\n",
    "y_test_pred = test_masks\n",
    "# print(y_test.shape)\n",
    "print(predicted_img.shape)\n",
    "cm = metrics.confusion_matrix(y_test_pred.reshape(-1), predicted_img.reshape(-1))\n",
    "print(cm, \"\\n\")\n",
    "print(classification_report(y_test_pred.reshape(-1), predicted_img.reshape(-1), digits=4))\n",
    "\n",
    "from keras.metrics import MeanIoU\n",
    "IOU_keras = MeanIoU(num_classes=2)\n",
    "IOU_keras.update_state(y_test_pred.reshape(-1), predicted_img.reshape(-1))\n",
    "print(\"Mean IoU = \", IOU_keras.result().numpy())\n",
    "values = np.array(IOU_keras.get_weights()).reshape(2, 2)\n",
    "class1_IoU = values[0,0]/(values[0,0] + values[0,1] + values[1,0])\n",
    "class2_IoU = values[1,1]/(values[1,1] + values[1,0] + values[0,1])\n",
    "# class3_IoU = values[2,2]/(values[2,2] + values[2,0] + values[2,1] + values[2,3] + values[0,2] + values[1,2] + values[3,2])\n",
    "# class4_IoU = values[3,3]/(values[3,3] + values[3,0] + values[3,1] + values[3,2] + values[0,3] + values[1,3] + values[2,3])\n",
    "print(\"class1 IoU = \", class1_IoU)\n",
    "print(\"class2 IoU = \", class2_IoU)\n",
    "# print(\"class3 IoU = \", class3_IoU)\n",
    "# print(\"class4 IoU = \", class4_IoU)\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "kappa_score = cohen_kappa_score(y_test_pred.reshape(-1), predicted_img.reshape(-1))\n",
    "print(\"Kappa:\", kappa_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f0d626-bbc3-4a09-9201-b4efb5fe1f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ramdomly check on test images\n",
    "image_number = random.randint(0, len(test_images)-1)\n",
    "predicted1 = np.expand_dims(test_list[0][image_number], 0)\n",
    "predicted2 = np.expand_dims(test_list[1][image_number], 0)\n",
    "# predicted3 = np.expand_dims(test_list[2][image_number], 0)\n",
    "predict_list = [predicted1, predicted2]\n",
    "\n",
    "prediction = (model.predict(predict_list))\n",
    "predicted_img=np.argmax(prediction, axis=3)[0,:,:]\n",
    "# print(prediction[0, 0, :, :])\n",
    "# print(prediction[0, 1, 1, :])\n",
    "# print(predicted_img)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(231)\n",
    "plt.title('Testing Image')\n",
    "plt.imshow(np.reshape((test_images[image_number, :, :, 2]), (256, 256, 1)))\n",
    "plt.subplot(232)\n",
    "plt.title('Testing Label')\n",
    "plt.imshow(np.reshape(test_masks[image_number], (256, 256, 1)))\n",
    "plt.subplot(233)\n",
    "plt.title('Prediction on test image')\n",
    "plt.imshow(np.reshape((predicted_img), (256, 256, 1)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6055b9-ce83-41b6-ba99-27078e2f7ca6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
