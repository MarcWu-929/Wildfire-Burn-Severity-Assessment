{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205b24cf-9dd0-40ab-b5d5-7a0dfb9d5f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from osgeo import gdal\n",
    "import pandas as pd\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import class_weight\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597b3831-4616-48e4-8390-0312589c0abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = []\n",
    "image_names = glob.glob(r\"C:\\Document\\University\\2023_Spring_Junior\\GEOG_491\\Dataset\\August_Complex\\Deep_learning\\256\\training_image\\images/*.tif\")\n",
    "image_names.sort()\n",
    "for img_path in image_names:\n",
    "      tiff_image = gdal.Open(img_path, 0)\n",
    "      band7 = tiff_image.GetRasterBand(7).ReadAsArray()\n",
    "      band8 = tiff_image.GetRasterBand(8).ReadAsArray()\n",
    "      band9 = tiff_image.GetRasterBand(9).ReadAsArray()\n",
    "\n",
    "      X = np.stack((band9, band8, band7), axis=-1)\n",
    "      train_images.append(X)\n",
    "\n",
    "train_images = np.array(train_images)\n",
    "print(np.mean(train_images))\n",
    "X_train = train_images\n",
    "print(X_train.shape)\n",
    "\n",
    "train_masks = []\n",
    "image_names = glob.glob(r\"C:\\Document\\University\\2023_Spring_Junior\\GEOG_491\\Dataset\\August_Complex\\Deep_learning\\mask\\ps\\multi\\truth_2\\train\\images/*.tif\")\n",
    "image_names.sort()\n",
    "for img_path in image_names:\n",
    "   tiff_image = gdal.Open(img_path, 0)\n",
    "   band1 = tiff_image.GetRasterBand(1).ReadAsArray()\n",
    "   train_masks.append(band1)\n",
    "\n",
    "train_masks = np.array(train_masks)\n",
    "y_train = train_masks\n",
    "print(y_train.shape)\n",
    "\n",
    "y_train_cat = to_categorical(train_masks, num_classes=4)\n",
    "y_train_cat = y_train_cat.astype(int)\n",
    "print(y_train_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e1b612-c585-4078-88de-f56d5685614e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sanity check, view few images\n",
    "import random\n",
    "import numpy as np\n",
    "image_number = random.randint(0, len(train_images)-1)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(121)\n",
    "plt.imshow(np.reshape((train_images[image_number, :, :, 2]), (256, 256, 1)))\n",
    "plt.subplot(122)\n",
    "plt.imshow(np.reshape(train_masks[image_number], (256, 256, 1)))\n",
    "plt.show()\n",
    "print(image_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6425a47-57db-43d4-a508-31ffc801c8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = []\n",
    "image_names = glob.glob(r\"C:\\Document\\University\\2023_Spring_Junior\\GEOG_491\\Dataset\\August_Complex\\Deep_learning\\256\\testing_image\\images/*.tif\")\n",
    "image_names.sort()\n",
    "for img_path in image_names:\n",
    "      tiff_image = gdal.Open(img_path, 0)\n",
    "      band7 = tiff_image.GetRasterBand(7).ReadAsArray()\n",
    "      band8 = tiff_image.GetRasterBand(8).ReadAsArray()\n",
    "      band9 = tiff_image.GetRasterBand(9).ReadAsArray()\n",
    "\n",
    "      X = np.stack((band9, band8, band7), axis=-1)\n",
    "      test_images.append(X)\n",
    "\n",
    "test_images = np.array(test_images)\n",
    "print(np.mean(test_images))\n",
    "print(test_images.shape)\n",
    "\n",
    "test_masks = []\n",
    "image_names = glob.glob(r\"C:\\Document\\University\\2023_Spring_Junior\\GEOG_491\\Dataset\\August_Complex\\Deep_learning\\mask\\ps\\multi\\truth_2\\test\\images/*.tif\")\n",
    "image_names.sort()\n",
    "for img_path in image_names:\n",
    "   tiff_image = gdal.Open(img_path, 0)\n",
    "   band1 = tiff_image.GetRasterBand(1).ReadAsArray()\n",
    "   test_masks.append(band1)\n",
    "\n",
    "test_masks = np.array(test_masks)\n",
    "print(np.unique(test_masks))\n",
    "\n",
    "y_test_cat = to_categorical(test_masks, num_classes=4)\n",
    "y_test_cat = y_test_cat.astype(int)\n",
    "print(y_test_cat.shape)\n",
    "print(np.unique(y_test_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaea5d75-738f-43fd-a704-1902c45e687e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Sanity check, view few images\n",
    "image_number = random.randint(0, len(test_images)-1)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(121)\n",
    "plt.imshow(np.reshape((test_images[image_number, :, :, 2]), (256, 256, 1)))\n",
    "plt.subplot(122)\n",
    "plt.imshow(np.reshape(test_masks[image_number], (256, 256, 1)))\n",
    "plt.show()\n",
    "print(image_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1810a3-c296-4de2-b898-5911fb4890d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Activation, multiply\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers, regularizers\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def conv_block(x, filter_size, size, dropout, batch_norm=False):\n",
    "\n",
    "    conv = layers.Conv2D(size, (filter_size, filter_size), padding=\"same\")(x)\n",
    "    if batch_norm is True:\n",
    "        conv = layers.BatchNormalization(axis=3)(conv)\n",
    "    conv = layers.Activation(\"relu\")(conv)\n",
    "\n",
    "    conv = layers.Conv2D(size, (filter_size, filter_size), padding=\"same\")(conv)\n",
    "    if batch_norm is True:\n",
    "        conv = layers.BatchNormalization(axis=3)(conv)\n",
    "    conv = layers.Activation(\"relu\")(conv)\n",
    "\n",
    "    if dropout > 0:\n",
    "        conv = layers.Dropout(dropout)(conv)\n",
    "\n",
    "    return conv\n",
    "\n",
    "\n",
    "def repeat_elem(tensor, rep):\n",
    "     return layers.Lambda(lambda x, repnum: K.repeat_elements(x, repnum, axis=3),\n",
    "                          arguments={'repnum': rep})(tensor)\n",
    "\n",
    "def gating_signal(input, out_size, batch_norm=False):\n",
    "\n",
    "    x = layers.Conv2D(out_size, (1, 1), padding='same')(input)\n",
    "    if batch_norm:\n",
    "        x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def attention_block(x, gating, inter_shape):\n",
    "    shape_x = K.int_shape(x)\n",
    "    shape_g = K.int_shape(gating)\n",
    "\n",
    "# Getting the x signal to the same shape as the gating signal\n",
    "    theta_x = layers.Conv2D(inter_shape, (2, 2), strides=(2, 2), padding='same')(x)  # 16\n",
    "    shape_theta_x = K.int_shape(theta_x)\n",
    "\n",
    "# Getting the gating signal to the same number of filters as the inter_shape\n",
    "    phi_g = layers.Conv2D(inter_shape, (1, 1), padding='same')(gating)\n",
    "    upsample_g = layers.Conv2DTranspose(inter_shape, (3, 3),\n",
    "                                 strides=(shape_theta_x[1] // shape_g[1], shape_theta_x[2] // shape_g[2]),\n",
    "                                 padding='same')(phi_g)  # 16\n",
    "\n",
    "    concat_xg = layers.add([upsample_g, theta_x])\n",
    "    act_xg = layers.Activation('relu')(concat_xg)\n",
    "    psi = layers.Conv2D(1, (1, 1), padding='same')(act_xg)\n",
    "    sigmoid_xg = layers.Activation('sigmoid')(psi)\n",
    "    shape_sigmoid = K.int_shape(sigmoid_xg)\n",
    "    upsample_psi = layers.UpSampling2D(size=(shape_x[1] // shape_sigmoid[1], shape_x[2] // shape_sigmoid[2]))(sigmoid_xg)  # 32\n",
    "\n",
    "    upsample_psi = repeat_elem(upsample_psi, shape_x[3])\n",
    "\n",
    "    y = layers.multiply([upsample_psi, x])\n",
    "\n",
    "    result = layers.Conv2D(shape_x[3], (1, 1), padding='same')(y)\n",
    "    result_bn = layers.BatchNormalization()(result)\n",
    "    return result_bn\n",
    "\n",
    "def res_conv_block(x, filter_size, size, dropout, batch_norm=False):\n",
    "\n",
    "    conv = layers.Conv2D(size, (filter_size, filter_size), padding='same')(x)\n",
    "    if batch_norm is True:\n",
    "        conv = layers.BatchNormalization(axis=3)(conv)\n",
    "    conv = layers.Activation('relu')(conv)\n",
    "\n",
    "    conv = layers.Conv2D(size, (filter_size, filter_size), padding='same')(conv)\n",
    "    if batch_norm is True:\n",
    "        conv = layers.BatchNormalization(axis=3)(conv)\n",
    "    #conv = layers.Activation('relu')(conv)    #Activation before addition with shortcut\n",
    "    if dropout > 0:\n",
    "        conv = layers.Dropout(dropout)(conv)\n",
    "\n",
    "    shortcut = layers.Conv2D(size, kernel_size=(1, 1), padding='same')(x)\n",
    "    if batch_norm is True:\n",
    "        shortcut = layers.BatchNormalization(axis=3)(shortcut)\n",
    "\n",
    "    res_path = layers.add([shortcut, conv])\n",
    "    res_path = layers.Activation('relu')(res_path)    #Activation after addition with shortcut (Original residual block)\n",
    "    return res_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab14d0a0-dc21-46fc-8363-9552a1ccdf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def UNet(input_shape, NUM_CLASSES=4, dropout_rate=0.1, batch_norm=True):\n",
    "\n",
    "    # network structure\n",
    "    FILTER_NUM = 16 # number of filters for the first layer\n",
    "    FILTER_SIZE = 3 # size of the convolutional filter\n",
    "    UP_SAMP_SIZE = 2 # size of upsampling filters\n",
    "\n",
    "\n",
    "    inputs = layers.Input(input_shape)\n",
    "\n",
    "    # Downsampling layers\n",
    "    # DownRes 1, convolution + pooling\n",
    "    conv_128 = conv_block(inputs, FILTER_SIZE, FILTER_NUM, dropout_rate, batch_norm)\n",
    "    pool_64 = layers.MaxPooling2D(pool_size=(2,2))(conv_128)\n",
    "    # DownRes 2\n",
    "    conv_64 = conv_block(pool_64, FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm)\n",
    "    pool_32 = layers.MaxPooling2D(pool_size=(2,2))(conv_64)\n",
    "    # DownRes 3\n",
    "    conv_32 = conv_block(pool_32, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)\n",
    "    pool_16 = layers.MaxPooling2D(pool_size=(2,2))(conv_32)\n",
    "    # DownRes 4\n",
    "    conv_16 = conv_block(pool_16, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)\n",
    "    pool_8 = layers.MaxPooling2D(pool_size=(2,2))(conv_16)\n",
    "    # DownRes 5, convolution only\n",
    "    conv_8 = conv_block(pool_8, FILTER_SIZE, 16*FILTER_NUM, dropout_rate, batch_norm)\n",
    "\n",
    "    # Upsampling layers\n",
    "\n",
    "    up_16 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(conv_8)\n",
    "    up_16 = layers.concatenate([up_16, conv_16], axis=3)\n",
    "    up_conv_16 = conv_block(up_16, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)\n",
    "    # UpRes 7\n",
    "\n",
    "    up_32 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_16)\n",
    "    up_32 = layers.concatenate([up_32, conv_32], axis=3)\n",
    "    up_conv_32 = conv_block(up_32, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)\n",
    "    # UpRes 8\n",
    "\n",
    "    up_64 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_32)\n",
    "    up_64 = layers.concatenate([up_64, conv_64], axis=3)\n",
    "    up_conv_64 = conv_block(up_64, FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm)\n",
    "    # UpRes 9\n",
    "\n",
    "    up_128 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_64)\n",
    "    up_128 = layers.concatenate([up_128, conv_128], axis=3)\n",
    "    up_conv_128 = conv_block(up_128, FILTER_SIZE, FILTER_NUM, dropout_rate, batch_norm)\n",
    "\n",
    "    # 1*1 convolutional layers\n",
    "\n",
    "    conv_final = layers.Conv2D(NUM_CLASSES, kernel_size=(1,1))(up_conv_128)\n",
    "    conv_final = layers.BatchNormalization(axis=3)(conv_final)\n",
    "    conv_final = layers.Activation('softmax')(conv_final)\n",
    "\n",
    "    # Model\n",
    "    model = models.Model(inputs, conv_final, name=\"UNet\")\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399124d6-63ff-4ab9-985a-cd03674da6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "def categorical_mean_iou_loss(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, y_pred.dtype) \n",
    "\n",
    "    # Calculate intersection and union\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=[1, 2])\n",
    "    union = K.sum(y_true, axis=[1, 2]) + K.sum(y_pred, axis=[1, 2]) - intersection\n",
    "\n",
    "    # Calculate mean IoU loss\n",
    "    iou = (intersection + K.epsilon()) / (union + K.epsilon())\n",
    "    mean_iou_loss = 1 - K.mean(iou)\n",
    "\n",
    "    return mean_iou_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078d9e54-23a7-4068-87dc-cc9f6a92f6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMeanIOU(tf.keras.metrics.MeanIoU):\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        return super().update_state(tf.argmax(y_true, axis=-1), tf.argmax(y_pred, axis=-1), sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a86d4e-322a-4063-9d3b-6fb0d4572d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "def get_model():\n",
    "    return UNet((256, 256, 3))\n",
    "model = get_model()\n",
    "model.compile(optimizer = 'adam', loss=categorical_mean_iou_loss, metrics = [MyMeanIOU(4)])\n",
    "# tf.keras.losses.CategoricalCrossentropy()\n",
    "# categorical_focal_loss(gamma=2.0, alpha=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4923eed8-966c-411a-bdf0-23719db23645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting model\n",
    "import time\n",
    "start_time = time.time()\n",
    "history = model.fit(train_images, y_train_cat,\n",
    "                    batch_size = 8,\n",
    "                    verbose=1,\n",
    "                    epochs=50,\n",
    "                    validation_split=0.1,\n",
    "                    # validation_data=(test_images, y_test_cat),\n",
    "                    shuffle=True)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(\"Training time: {:.2f} seconds\".format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a3d989-e6d2-4478-b94b-5adbdefd7666",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "predicted = np.expand_dims(test_images, 0)\n",
    "prediction = (model.predict(test_images))\n",
    "print(prediction.shape)\n",
    "predicted_img = np.argmax(prediction, axis=3)[:,:,:]\n",
    "y_test_pred = test_masks\n",
    "print(predicted_img.shape)\n",
    "cm = metrics.confusion_matrix(y_test_pred.reshape(-1), predicted_img.reshape(-1))\n",
    "print(cm, \"\\n\")\n",
    "print(classification_report(y_test_pred.reshape(-1), predicted_img.reshape(-1), digits=4))\n",
    "\n",
    "from keras.metrics import MeanIoU\n",
    "IOU_keras = MeanIoU(num_classes=4)\n",
    "IOU_keras.update_state(y_test_pred.reshape(-1), predicted_img.reshape(-1))\n",
    "print(\"Mean IoU = \", IOU_keras.result().numpy())\n",
    "values = np.array(IOU_keras.get_weights()).reshape(4, 4)\n",
    "class1_IoU = values[0,0]/(values[0,0] + values[0,1] + values[0,2] + values[0,3] + values[1,0] + values[2,0] + values[3,0])\n",
    "class2_IoU = values[1,1]/(values[1,1] + values[1,0] + values[1,2] + values[1,3] + values[0,1] + values[2,1] + values[3,1])\n",
    "class3_IoU = values[2,2]/(values[2,2] + values[2,0] + values[2,1] + values[2,3] + values[0,2] + values[1,2] + values[3,2])\n",
    "class4_IoU = values[3,3]/(values[3,3] + values[3,0] + values[3,1] + values[3,2] + values[0,3] + values[1,3] + values[2,3])\n",
    "print(\"class1 IoU = \", class1_IoU)\n",
    "print(\"class2 IoU = \", class2_IoU)\n",
    "print(\"class3 IoU = \", class3_IoU)\n",
    "print(\"class4 IoU = \", class4_IoU)\n",
    "\n",
    "m = tf.keras.metrics.Accuracy()\n",
    "m.update_state(y_test_pred.reshape(-1), predicted_img.reshape(-1))\n",
    "print('\\n', 'Accuracy = ', m.result().numpy())\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "kappa_score = cohen_kappa_score(y_test_pred.reshape(-1), predicted_img.reshape(-1))\n",
    "print(\"Kappa:\", kappa_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f0d626-bbc3-4a09-9201-b4efb5fe1f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomly check on train images\n",
    "image_number = random.randint(0, len(train_images)-1)\n",
    "predicted = np.expand_dims(train_images[image_number], 0)\n",
    "prediction = (model.predict(predicted))\n",
    "predicted_img=np.argmax(prediction, axis=3)[0,:,:]\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(231)\n",
    "plt.title('Testing Image')\n",
    "plt.imshow(np.reshape((train_images[image_number, :, :, 2]), (256, 256, 1)))\n",
    "plt.subplot(232)\n",
    "plt.title('Testing Label')\n",
    "plt.imshow(np.reshape(train_masks[image_number], (256, 256, 1)))\n",
    "plt.subplot(233)\n",
    "plt.title('Prediction on test image')\n",
    "plt.imshow(np.reshape((predicted_img), (256, 256, 1)))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
