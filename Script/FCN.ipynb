{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205b24cf-9dd0-40ab-b5d5-7a0dfb9d5f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from osgeo import gdal\n",
    "import pandas as pd\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import class_weight\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597b3831-4616-48e4-8390-0312589c0abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = []\n",
    "image_names = glob.glob(r\"C:\\Document\\University\\2023_Spring_Junior\\GEOG_491\\Dataset\\August_Complex\\Deep_learning\\256\\training_image\\images/*.tif\")\n",
    "image_names.sort()\n",
    "for img_path in image_names:\n",
    "      tiff_image = gdal.Open(img_path, 0)\n",
    "      band7 = tiff_image.GetRasterBand(7).ReadAsArray()\n",
    "      band8 = tiff_image.GetRasterBand(8).ReadAsArray()\n",
    "      band9 = tiff_image.GetRasterBand(9).ReadAsArray()\n",
    "\n",
    "      X = np.stack((band9, band8, band7), axis=-1)\n",
    "      train_images.append(X)\n",
    "\n",
    "train_images = np.array(train_images)\n",
    "print(np.mean(train_images))\n",
    "X_train = train_images\n",
    "print(X_train.shape)\n",
    "\n",
    "train_masks = []\n",
    "image_names = glob.glob(r\"C:\\Document\\University\\2023_Spring_Junior\\GEOG_491\\Dataset\\August_Complex\\Deep_learning\\mask\\ps\\multi\\truth_2\\train\\images/*.tif\")\n",
    "image_names.sort()\n",
    "for img_path in image_names:\n",
    "   tiff_image = gdal.Open(img_path, 0)\n",
    "   band1 = tiff_image.GetRasterBand(1).ReadAsArray()\n",
    "   train_masks.append(band1)\n",
    "\n",
    "train_masks = np.array(train_masks)\n",
    "y_train = train_masks\n",
    "print(y_train.shape)\n",
    "\n",
    "y_train_cat = to_categorical(train_masks, num_classes=4)\n",
    "y_train_cat = y_train_cat.astype(int)\n",
    "print(y_train_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e1b612-c585-4078-88de-f56d5685614e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sanity check, view few images\n",
    "import random\n",
    "import numpy as np\n",
    "image_number = random.randint(0, len(train_images)-1)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(121)\n",
    "plt.imshow(np.reshape((train_images[image_number, :, :, 2]), (256, 256, 1)))\n",
    "plt.subplot(122)\n",
    "plt.imshow(np.reshape(train_masks[image_number], (256, 256, 1)))\n",
    "plt.show()\n",
    "print(image_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6425a47-57db-43d4-a508-31ffc801c8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = []\n",
    "image_names = glob.glob(r\"C:\\Document\\University\\2023_Spring_Junior\\GEOG_491\\Dataset\\August_Complex\\Deep_learning\\256\\testing_image\\images/*.tif\")\n",
    "image_names.sort()\n",
    "for img_path in image_names:\n",
    "      tiff_image = gdal.Open(img_path, 0)\n",
    "      band7 = tiff_image.GetRasterBand(7).ReadAsArray()\n",
    "      band8 = tiff_image.GetRasterBand(8).ReadAsArray()\n",
    "      band9 = tiff_image.GetRasterBand(9).ReadAsArray()\n",
    "\n",
    "      X = np.stack((band9, band8, band7), axis=-1)\n",
    "      test_images.append(X)\n",
    "\n",
    "test_images = np.array(test_images)\n",
    "print(np.mean(test_images))\n",
    "print(test_images.shape)\n",
    "\n",
    "test_masks = []\n",
    "image_names = glob.glob(r\"C:\\Document\\University\\2023_Spring_Junior\\GEOG_491\\Dataset\\August_Complex\\Deep_learning\\mask\\ps\\multi\\truth_2\\test\\images/*.tif\")\n",
    "image_names.sort()\n",
    "for img_path in image_names:\n",
    "   tiff_image = gdal.Open(img_path, 0)\n",
    "   band1 = tiff_image.GetRasterBand(1).ReadAsArray()\n",
    "   test_masks.append(band1)\n",
    "\n",
    "test_masks = np.array(test_masks)\n",
    "print(np.unique(test_masks))\n",
    "\n",
    "y_test_cat = to_categorical(test_masks, num_classes=4)\n",
    "y_test_cat = y_test_cat.astype(int)\n",
    "print(y_test_cat.shape)\n",
    "print(np.unique(y_test_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaea5d75-738f-43fd-a704-1902c45e687e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Sanity check, view few images\n",
    "image_number = random.randint(0, len(test_images)-1)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(121)\n",
    "plt.imshow(np.reshape((test_images[image_number, :, :, 2]), (256, 256, 1)))\n",
    "plt.subplot(122)\n",
    "plt.imshow(np.reshape(test_masks[image_number], (256, 256, 1)))\n",
    "plt.show()\n",
    "print(image_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab14d0a0-dc21-46fc-8363-9552a1ccdf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose, BatchNormalization, Activation\n",
    "\n",
    "# Define the FCN model\n",
    "def FCN(n_classes=4, IMG_HEIGHT=256, IMG_WIDTH=256, IMG_CHANNELS=3):\n",
    "    # Input\n",
    "    inputs = keras.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "\n",
    "    # Encoder\n",
    "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    # Decoder\n",
    "    upconv3 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(pool3)\n",
    "    upconv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(upconv3)\n",
    "    upconv3 = BatchNormalization()(upconv3)\n",
    "    upconv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(upconv3)\n",
    "    upconv3 = BatchNormalization()(upconv3)\n",
    "\n",
    "    upconv2 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(upconv3)\n",
    "    upconv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(upconv2)\n",
    "    upconv2 = BatchNormalization()(upconv2)\n",
    "    upconv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(upconv2)\n",
    "    upconv2 = BatchNormalization()(upconv2)\n",
    "\n",
    "    upconv1 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(upconv2)\n",
    "    upconv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(upconv1)\n",
    "    upconv1 = BatchNormalization()(upconv1)\n",
    "    upconv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(upconv1)\n",
    "    upconv1 = BatchNormalization()(upconv1)\n",
    "\n",
    "    # Output\n",
    "    outputs = Conv2D(n_classes, (1, 1), activation='softmax', padding='same')(upconv1)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399124d6-63ff-4ab9-985a-cd03674da6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "def categorical_mean_iou_loss(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, y_pred.dtype)  \n",
    "\n",
    "    # Calculate intersection and union\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=[1, 2])\n",
    "    union = K.sum(y_true, axis=[1, 2]) + K.sum(y_pred, axis=[1, 2]) - intersection\n",
    "\n",
    "    # Calculate mean IoU loss\n",
    "    iou = (intersection + K.epsilon()) / (union + K.epsilon())\n",
    "    mean_iou_loss = 1 - K.mean(iou)\n",
    "\n",
    "    return mean_iou_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078d9e54-23a7-4068-87dc-cc9f6a92f6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMeanIOU(tf.keras.metrics.MeanIoU):\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        return super().update_state(tf.argmax(y_true, axis=-1), tf.argmax(y_pred, axis=-1), sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a86d4e-322a-4063-9d3b-6fb0d4572d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.000001)\n",
    "def get_model():\n",
    "    return FCN(n_classes=4, IMG_HEIGHT=256, IMG_WIDTH=256, IMG_CHANNELS=3)\n",
    "model = get_model()\n",
    "model.compile(optimizer = 'adam', loss=categorical_mean_iou_loss, metrics = [MyMeanIOU(4)])\n",
    "# tf.keras.losses.CategoricalCrossentropy()\n",
    "# categorical_focal_loss(gamma=2.0, alpha=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4923eed8-966c-411a-bdf0-23719db23645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting model\n",
    "import time\n",
    "start_time = time.time()\n",
    "history = model.fit(train_images, y_train_cat,\n",
    "                    batch_size = 8,\n",
    "                    verbose=1,\n",
    "                    epochs=50,\n",
    "                    validation_split=0.1,\n",
    "                    # validation_data=(test_images, y_test_cat),\n",
    "                    shuffle=True)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(\"Training time: {:.2f} seconds\".format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a3d989-e6d2-4478-b94b-5adbdefd7666",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "predicted = np.expand_dims(test_images, 0)\n",
    "prediction = (model.predict(test_images))\n",
    "print(prediction.shape)\n",
    "predicted_img = np.argmax(prediction, axis=3)[:,:,:]\n",
    "y_test_pred = test_masks\n",
    "# print(y_test.shape)\n",
    "print(predicted_img.shape)\n",
    "cm = metrics.confusion_matrix(y_test_pred.reshape(-1), predicted_img.reshape(-1))\n",
    "print(cm, \"\\n\")\n",
    "print(classification_report(y_test_pred.reshape(-1), predicted_img.reshape(-1), digits=4))\n",
    "\n",
    "from keras.metrics import MeanIoU\n",
    "IOU_keras = MeanIoU(num_classes=4)\n",
    "IOU_keras.update_state(y_test_pred.reshape(-1), predicted_img.reshape(-1))\n",
    "print(\"Mean IoU = \", IOU_keras.result().numpy())\n",
    "values = np.array(IOU_keras.get_weights()).reshape(4, 4)\n",
    "class1_IoU = values[0,0]/(values[0,0] + values[0,1] + values[0,2] + values[0,3] + values[1,0] + values[2,0] + values[3,0])\n",
    "class2_IoU = values[1,1]/(values[1,1] + values[1,0] + values[1,2] + values[1,3] + values[0,1] + values[2,1] + values[3,1])\n",
    "class3_IoU = values[2,2]/(values[2,2] + values[2,0] + values[2,1] + values[2,3] + values[0,2] + values[1,2] + values[3,2])\n",
    "class4_IoU = values[3,3]/(values[3,3] + values[3,0] + values[3,1] + values[3,2] + values[0,3] + values[1,3] + values[2,3])\n",
    "print(\"class1 IoU = \", class1_IoU)\n",
    "print(\"class2 IoU = \", class2_IoU)\n",
    "print(\"class3 IoU = \", class3_IoU)\n",
    "print(\"class4 IoU = \", class4_IoU)\n",
    "\n",
    "m = tf.keras.metrics.Accuracy()\n",
    "m.update_state(y_test_pred.reshape(-1), predicted_img.reshape(-1))\n",
    "print('\\n', 'Accuracy = ', m.result().numpy())\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "kappa_score = cohen_kappa_score(y_test_pred.reshape(-1), predicted_img.reshape(-1))\n",
    "print(\"Kappa:\", kappa_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f0d626-bbc3-4a09-9201-b4efb5fe1f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomly check on train images\n",
    "image_number = random.randint(0, len(train_images)-1)\n",
    "predicted = np.expand_dims(train_images[image_number], 0)\n",
    "prediction = (model.predict(predicted))\n",
    "predicted_img=np.argmax(prediction, axis=3)[0,:,:]\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(231)\n",
    "plt.title('Testing Image')\n",
    "plt.imshow(np.reshape((train_images[image_number, :, :, 2]), (256, 256, 1)))\n",
    "plt.subplot(232)\n",
    "plt.title('Testing Label')\n",
    "plt.imshow(np.reshape(train_masks[image_number], (256, 256, 1)))\n",
    "plt.subplot(233)\n",
    "plt.title('Prediction on test image')\n",
    "plt.imshow(np.reshape((predicted_img), (256, 256, 1)))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
